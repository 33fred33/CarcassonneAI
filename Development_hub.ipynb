{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Carcassonne_Game.Carcassonne import CarcassonneState\n",
    "from TicTacToe_Game.TicTacToe import TicTacToeState \n",
    "from Function_Optimisation_Game.Function_Optimisation import FunctionOptimisationState\n",
    "from player.Player import RandomPlayer\n",
    "from player.MCTS_Player import MCTSPlayer\n",
    "from player.MCTS_RAVE_Player import MCTS_RAVEPlayer\n",
    "from player.MCTS_ES_BACK_Player import MCTS_ES_BACK_Player\n",
    "from player.MCTS_ES_BACK_SEM_Player import MCTS_ES_BACK_SEM_Player\n",
    "\n",
    "import Experimental_Setup as exps\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "#from plotly.tools import make_subplots\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import ast\n",
    "import random\n",
    "import math\n",
    "import statistics as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from scipy.stats import bernoulli\n",
    "from scipy import optimize\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file created - logs\\FO\\Vanilla_MCTS_f5_c0.5\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f5_c1\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f5_c1.4142135623730951\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f5_c2\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f5_c3\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f6_c0.5\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f6_c1\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f6_c1.4142135623730951\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f6_c2\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f6_c3\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f7_c0.5\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f7_c1\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f7_c1.4142135623730951\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f7_c2\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f7_c3\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f8_c0.5\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f8_c1\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f8_c1.4142135623730951\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f8_c2\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f8_c3\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f9_c0.5\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f9_c1\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f9_c1.4142135623730951\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f9_c2\n",
      "Log file created - logs\\FO\\Vanilla_MCTS_f9_c3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for f in [5,6,7,8,9]:\n",
    "   #for its in [5000]:\n",
    "   for c in [0.5,1,math.sqrt(2),2,3]:\n",
    "      exps.fo_experiment(func_index=f,\n",
    "                  random_seed=0,\n",
    "                  experiment_type=\"1p\",\n",
    "                  player_dicts = [{\"type\":\"VMCTS\", \"c\":c}],\n",
    "                  runs = 30,\n",
    "                  splits = 2,\n",
    "                  ranges = [[0,1],[0,1]],\n",
    "                  minimum_step=0.00001,\n",
    "                  #Logs data\n",
    "                  log_path = [\"FO\",\"Vanilla_MCTS_f\"+str(f)+\"_c\"+str(c)],\n",
    "                  logs_divisions=3,\n",
    "                  tree_data=True,)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Collect_FO_logs(logs_path = \"logs/FO\", output_name = \"collective_logs.csv\", exp_names=None, include_tree_logs = False,  output_tree_name = \"collective_tree_logs.csv\"):\n",
    "    \"\"\"\n",
    "    1 player\n",
    "    Collects data in \"collective_tree_logs.csv\".\n",
    "    Logs names should be saved as \"logs_path/Results_f0_c0.5\" where f is the function, c is the parameter\n",
    "    Logs in that folder should contain \"Final_Player_logs.csv\" and \"Parameter_logs.csv\"\n",
    "    \"\"\"\n",
    "        \n",
    "    if exp_names is None:\n",
    "        exp_names = [ item for item in os.listdir(logs_path) if os.path.isdir(os.path.join(logs_path, item)) ]\n",
    "        \n",
    "    all_data = []\n",
    "    all_tree_data = []\n",
    "    final_df = pd.DataFrame()\n",
    "    final_tree_df = pd.DataFrame()\n",
    "    for i,exp_name in enumerate(exp_names):\n",
    "        data = pd.read_csv(os.path.join(logs_path, exp_name, \"Final_Player_logs.csv\"))\n",
    "        pars = pd.read_csv(os.path.join(logs_path, exp_name, \"Parameter_logs.csv\"))\n",
    "        tree_data = pd.read_csv(os.path.join(logs_path, exp_name, \"Tree_data.csv\"))\n",
    "\n",
    "        if \"Player_0_name\" in pars.columns:\n",
    "            player_name = pars[\"Player_0_name\"][0]\n",
    "        else:\n",
    "            player_name = exp_name.split(\"_f\")[0]\n",
    "        if \"func_index\" in pars.columns:\n",
    "            func_index = pars[\"func_index\"][0]\n",
    "        else:\n",
    "            func_index = exp_name.split(\"_f\")[1].split(\"_\")[0]\n",
    "        if \"Player_0_c\" in pars.columns or \"c_param\" in pars.columns:\n",
    "            if \"Player_0_c\" in pars.columns: c_param = pars[\"Player_0_c\"][0]\n",
    "    \n",
    "        data[\"Player\"] = [player_name for _ in range(len(data))]\n",
    "        data[\"function\"] = [func_index for _ in range(len(data))]\n",
    "        data[\"c\"] = [c_param for _ in range(len(data))]\n",
    "        data[\"expname\"] = [exp_name for _ in range(len(data))]\n",
    "        data[\"Params\"] = [pars.to_dict() for _ in range(len(data))]\n",
    "        all_data.append(data)\n",
    "\n",
    "        tree_data[\"Player\"] = [player_name for _ in range(len(tree_data))]\n",
    "        tree_data[\"function\"] = [func_index for _ in range(len(tree_data))]\n",
    "        tree_data[\"c\"] = [c_param for _ in range(len(tree_data))]\n",
    "        tree_data[\"expname\"] = [exp_name for _ in range(len(tree_data))]\n",
    "        tree_data[\"Params\"] = [pars.to_dict() for _ in range(len(tree_data))]\n",
    "        all_tree_data.append(tree_data)\n",
    "  \n",
    "    final_df = pd.concat(all_data)\n",
    "    final_df.to_csv(os.path.join(logs_path, output_name), index=False)\n",
    "\n",
    "    final_tree_df = pd.concat(all_tree_data)\n",
    "    final_tree_df.to_csv(os.path.join(logs_path, output_tree_name), index=False)\n",
    "\n",
    "exp_names = [ item for item in os.listdir(\"logs/FO\") if os.path.isdir(os.path.join(\"logs/FO\", item)) ]\n",
    "exp_names_filtered = []\n",
    "for name in exp_names:\n",
    "    for distinctive in [\"_f5_\",\"_f6_\",\"_f7_\",\"_f8_\",\"_f9_\"]:\n",
    "        if distinctive in name:\n",
    "            exp_names_filtered.append(name)\n",
    "            break\n",
    "Collect_FO_logs(exp_names=exp_names_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots to compare different algorithms in the same function - updated\n",
    "\n",
    "\n",
    "\n",
    "dummy_state = FunctionOptimisationState(players=[None], function=0, ranges=[[0,1]], splits=2)\n",
    "functions = dummy_state.function_list\n",
    "join = \"/\"\n",
    "logs_path = \"logs/Old/FO\"\n",
    "data = pd.read_csv(logs_path + join + \"collective_tree_logs.csv\")\n",
    "n_buckets = 128\n",
    "f_max_locations = [0.5,0.867,None,0.1,0.1]\n",
    "\n",
    "for f_index in [0,1,2,3,4]:\n",
    "   agents_names = data[\"player\"].unique()\n",
    "   print(agents_names)\n",
    "   c_params = data[\"c_param\"].unique()\n",
    "   c_params.sort()\n",
    "   generic_name = \"MCTS_c\"\n",
    "   agents_names = [x for x in agents_names]\n",
    "   names = []\n",
    "   data_list = []\n",
    "\n",
    "   #order names\n",
    "   for c in c_params:\n",
    "      string_c = str(c)\n",
    "      if string_c.split(\".\")[-1] == \"0\":\n",
    "            string_c = string_c[:-2]\n",
    "      names.append(generic_name + string_c)\n",
    "   for name in agents_names:\n",
    "      if \"SE_MCTS\" in name:\n",
    "            names.append(name)\n",
    "   for name in names:\n",
    "      temp_data = exps.get_subset(data, name, f_index)\n",
    "      data_list.append(temp_data)\n",
    "   \n",
    "   treated_names = []\n",
    "   for it,st in enumerate(names):\n",
    "      new_string = st.replace(\"_c\",\" C = \")\n",
    "      new_string = new_string.replace(\"1.414\",\"\\u221A\\u03052\\u0305fred\")\n",
    "      new_string = new_string.split(\"fred\")[0]\n",
    "      if \"SE_MCTS\" in new_string:\n",
    "            if \"2600\" in new_string:\n",
    "               new_string = \"SIEA_MCTS 2600 iterations\"\n",
    "            else:\n",
    "               new_string = \"SIEA_MCTS 5000 iterations\"\n",
    "      treated_names.append(new_string)\n",
    "   #plot = exps.show_search(data_list, functions[f_index], \"\", 3, n_buckets = n_buckets, subplot_titles = treated_names+[\"Function \"+str(f_index+1)], max_x_location=f_max_locations[f_index], y_ref_value=None)\n",
    "   plot = exps.show_search(data_list, functions[f_index], \"Exploration and exploitation distribution for Function \" + str(f_index+1) + \".\" , 3, n_buckets = n_buckets, subplot_titles = [\"Function \"+str(f_index+1)] + treated_names, max_x_location=f_max_locations[f_index], y_ref_value=None)\n",
    "   plot.write_image(os.path.join(logs_path, \"F\" + str(f_index+1) + \"_results\"+ str(n_buckets) + '.png'))#, width=800, height=800)\n",
    "   plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot depth by iteration\n",
    "\n",
    "dummy_state = FunctionOptimisationState(players=[None], function=0, ranges=[[0,1]], splits=2)\n",
    "functions = dummy_state.function_list\n",
    "join = \"/\"\n",
    "logs_path = \"logs/Old/FO\"\n",
    "output_name = \"collective_tree_logs.csv\"\n",
    "data = pd.read_csv(logs_path + join + \"collective_tree_logs.csv\")\n",
    "n_buckets = 400\n",
    "f_max_locations = [0.5,0.867,None,0.1,0.1]\n",
    "\n",
    "for f_index in [0]:#,1,2,3,4]:\n",
    "   agents_names = data[\"player\"].unique()\n",
    "   #print(agents_names)\n",
    "   c_params = data[\"c_param\"].unique()\n",
    "   c_params.sort()\n",
    "   generic_name = \"MCTS_c\"\n",
    "   agents_names = [x for x in agents_names]\n",
    "   names = []\n",
    "   data_list = []\n",
    "\n",
    "   #order names\n",
    "   for c in c_params:\n",
    "      string_c = str(c)\n",
    "      if string_c.split(\".\")[-1] == \"0\":\n",
    "         string_c = string_c[:-2]\n",
    "      names.append(generic_name + string_c)\n",
    "   for name in agents_names:\n",
    "      if \"SE_MCTS\" in name:\n",
    "         names.append(name)\n",
    "   for name in names:\n",
    "      temp_data = exps.get_subset(data, name, f_index)\n",
    "      data_list.append(temp_data)\n",
    "   \n",
    "   treated_names = []\n",
    "   temp_names = [x for x in names]\n",
    "   for it,st in enumerate(temp_names):\n",
    "      new_string = st.replace(\"_c\",\" C = \")\n",
    "      new_string = new_string.replace(\"1.414\",\"sqrt(2)fred\")\n",
    "      new_string = new_string.split(\"fred\")[0]\n",
    "      if \"SE_MCTS\" in new_string:\n",
    "         if \"2600\" in new_string:\n",
    "            new_string = \"SE_MCTS partial simulations\"\n",
    "            #continue\n",
    "         else:\n",
    "            new_string = \"SIEA_MCTS complete simulations\"\n",
    "      treated_names.append(new_string)\n",
    "\n",
    "   for i,df in enumerate(data_list):\n",
    "      df['player'] = df['player'].replace([names[i]],treated_names[i])\n",
    "\n",
    "   for i,name in enumerate(treated_names):\n",
    "      if name == \"SE_MCTS partial simulations\":\n",
    "         del data_list[i]\n",
    "   \n",
    "   #plot = exps.show_search(data_list, functions[f_index], \"\", 3, n_buckets = n_buckets, type=\"divisions\")#, subplot_titles = treated_names+[\"Function \"+str(f_index+1)], max_x_location=f_max_locations[f_index], y_ref_value=None)\n",
    "   plot = exps.show_search_depth(data_list, \"Average expansion depth by iteration. Function \" + str(f_index+1), 30, 10)\n",
    "   #depth_plot.write_image(os.path.join(logs_path, \"depth\" + str(f_index) + '.png'), width=600, height=350)\n",
    "   #plot = show_search2(data_list, functions[f_index], \"\", 3, n_buckets = 200, type=\"divisions\", subplot_titles = agents_names+[\"Function \"+str(f_index)])\n",
    "   plot.show()\n",
    "   #depth_plot.write_image(os.path.join(logs_path, \"depth_f\" + str(f_index) + '.png'), width=800, height=400)\n",
    "   #plot.write_image(os.path.join(logs_path, \"depth_histo_max_2k_f\" + str(f_index) + '.png'), width=800, height=800)\n",
    "   #plot.write_image(os.path.join(logs_path, \"Average_depth_by_iteration_f\" + str(f_index+1) + '.png'), width=800, height=400)\n",
    "   colors = [\"#000000\"\n",
    "                , \"#B10909\" #red\n",
    "                ,  \"#5B8C5A\"#green\n",
    "                ,\"#56638A\" #blue-purple\n",
    "                , \"#EC7316\" #orange\n",
    "                ,  \"#FC738C\" ] #pink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_surface(state):\n",
    "    assert state.function_index in [5,6,7,8,9,10]\n",
    "    granularity = 1000\n",
    "    x, y = np.linspace(state.ranges[0][0], state.ranges[0][1], granularity), np.linspace(state.ranges[1][0], state.ranges[1][1], granularity)\n",
    "    z_dict = {}\n",
    "    for yi in y:\n",
    "        z_dict[yi]=[]\n",
    "        for xi in x:\n",
    "            z_dict[yi].append(state.function([xi,yi]))\n",
    "    z = pd.DataFrame(z_dict).values\n",
    "    fig = go.Figure(data=[go.Surface(z=z, x=x, y=y,\n",
    "                                    contours = {\n",
    "                                        #\"x\": {\"show\": True, \"start\": 0, \"end\": 1, \"size\": 0.05, \"color\":\"white\"},\n",
    "                                        \"z\": {\"show\": True, \"start\": 0, \"end\": 1, \"size\": 0.1, \"color\":\"white\"}\n",
    "                                    })])\n",
    "    fig.update_traces(contours_z=dict(show=True, usecolormap=True,\n",
    "                                    highlightcolor=\"limegreen\", project_z=True))\n",
    "    fig.update_layout(#title='Mt Bruno Elevation',\n",
    "                    autosize=False,\n",
    "                    scene_camera_eye=dict(x=2, y=1, z=-0.5),\n",
    "                    width=500, height=500,\n",
    "                    margin=dict(l=30, r=50, b=10, t=10),\n",
    "                    scene = {\n",
    "                        #\"xaxis\": {\"nticks\": 5},\n",
    "                        #\"zaxis\": {\"nticks\": 5},\n",
    "                        \"aspectratio\": {\"x\": 1, \"y\": 1, \"z\": 1}}\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "def fo_function_analysis_2d(fo_state, max_depth=3, minimum_step_limit = None, print_logs=False):\n",
    "   \"\"\"Returns a figure with a 2d histogram plotting the function landscape as MCTS will se it. Manual (Fast)\n",
    "    Usage example:\n",
    "    random_player = RandomPlayer()\n",
    "    dummy_state = FunctionOptimisationState(players=[random_player], function=6, ranges=[[0,1],[0,1]], minimum_step=0.001, splits=3)\n",
    "    fig = exps.fo_function_analysis_2d(dummy_state, print_logs=True, max_depth=4)\n",
    "    fig.show()\n",
    "   \"\"\"\n",
    "   #Find evaluation points\n",
    "   stop = {}\n",
    "   start = {}\n",
    "   max_depth_step = {}\n",
    "   x = {}\n",
    "   division_size = {}\n",
    "   dimensions = len(fo_state.ranges)\n",
    "   if minimum_step_limit is not None:\n",
    "       minimum_step = minimum_step_limit\n",
    "   else:\n",
    "       minimum_step = fo_state.minimum_step\n",
    "\n",
    "   #splits by dimension\n",
    "   for d in range(dimensions):\n",
    "      \n",
    "      stop[d] = fo_state.ranges[d][1]\n",
    "      start[d] = fo_state.ranges[d][0]\n",
    "      max_depth_step[d] = (stop[d]-start[d])/(fo_state.splits**max_depth)\n",
    "      division_size[d] = stop[d] - start[d]\n",
    "      while division_size[d] > minimum_step:\n",
    "         division_size[d] = division_size[d]/fo_state.splits   \n",
    "\n",
    "      #get central points\n",
    "      x[d] = []   \n",
    "      next_start = start[d]\n",
    "      center_distance = division_size[d]/2\n",
    "      while next_start+center_distance < stop[d]:\n",
    "         next_stop = next_start + division_size[d]\n",
    "         x[d].append(next_start+center_distance) #gets the value in the middle\n",
    "         next_start = next_stop\n",
    "\n",
    "   fig_x = {}\n",
    "   fig_y = {}\n",
    "   fig_z = {}\n",
    "   for current_depth in reversed([md+1 for md in range(max_depth)]):\n",
    "      depth_step = {}\n",
    "      for d in range(dimensions):\n",
    "         depth_step[d] = (stop[d]-start[d])/(fo_state.splits**current_depth)\n",
    "\n",
    "      if max_depth == current_depth:\n",
    "         granular_x = x[0]\n",
    "         granular_y = x[1]\n",
    "      else:\n",
    "         granular_x = fig_x[current_depth+1]\n",
    "         granular_y = fig_y[current_depth+1]\n",
    "         granular_z = {}\n",
    "         for i in range(len(granular_x)):\n",
    "            granular_z[(granular_x[i], granular_y[i])] = fig_z[current_depth+1][i]\n",
    "\n",
    "      all_depth_steps = {}\n",
    "      for d in range(dimensions):\n",
    "         all_depth_steps[d] = [[i*depth_step[d], (i+0.5)*depth_step[d], (i+1)*depth_step[d]] for i in range(fo_state.splits**current_depth)]\n",
    "         all_depth_steps[d][0][0] = start[d]\n",
    "         all_depth_steps[d][-1][2] = stop[d]\n",
    "\n",
    "      avg_by_y={}\n",
    "      for j in granular_y:\n",
    "         avg_by_y[j] = {}\n",
    "         steps = 0\n",
    "         count = 0\n",
    "         accum = 0\n",
    "         for i in granular_x:\n",
    "            if i > all_depth_steps[0][steps][2]:\n",
    "               avg_by_y[j][all_depth_steps[0][steps][1]] = accum/count\n",
    "               count = 0\n",
    "               accum = 0\n",
    "               steps += 1\n",
    "            if max_depth == current_depth:\n",
    "               accum = accum + fo_state.function([i,j])\n",
    "            else:\n",
    "               accum = accum + granular_z[(i,j)]\n",
    "            count += 1\n",
    "         avg_by_y[j][all_depth_steps[0][steps][1]] = accum/count\n",
    "         all_x_keys = avg_by_y[j].keys()\n",
    "\n",
    "      fig_x[current_depth]=[]\n",
    "      fig_y[current_depth]=[]\n",
    "      fig_z[current_depth]=[]\n",
    "      for i in all_x_keys:\n",
    "         steps = 0\n",
    "         count = 0\n",
    "         accum = 0\n",
    "         for j in avg_by_y.keys():\n",
    "            if j > all_depth_steps[1][steps][2]:\n",
    "               fig_x[current_depth].append(i)\n",
    "               fig_y[current_depth].append(all_depth_steps[1][steps][1])\n",
    "               fig_z[current_depth].append(accum/count)\n",
    "               count = 0\n",
    "               accum = 0\n",
    "               steps += 1\n",
    "            accum = accum + avg_by_y[j][i]\n",
    "            count += 1\n",
    "         fig_x[current_depth].append(i)\n",
    "         fig_y[current_depth].append(all_depth_steps[1][steps][1])\n",
    "         fig_z[current_depth].append(accum/count)\n",
    "\n",
    "   #create subplots\n",
    "   plot_pixels = 150\n",
    "   top_space = 30\n",
    "   vertical_spacing = 0.03\n",
    "   n_plots = max_depth\n",
    "   row_heights = [1/n_plots for _ in range(n_plots)]\n",
    "   column_widths = [1]\n",
    "   fig = make_subplots(\n",
    "      rows=len(row_heights)\n",
    "      ,cols=len(column_widths)\n",
    "      ,shared_xaxes=True\n",
    "      ,vertical_spacing=vertical_spacing\n",
    "      ,row_heights = row_heights\n",
    "      ,column_widths = column_widths\n",
    "      ,subplot_titles=[\"Tree Depth \" + str(d+1) for d in range(max_depth)]\n",
    "      #,specs=[[{\"secondary_y\": True}] for _ in range(len(column_widths))]\n",
    "      )\n",
    "   \n",
    "   #add analysis plots\n",
    "   colorbar_padding = 0.1 #a percetage of the lenght of the colorbars\n",
    "   show_legend = True\n",
    "   for d in range(1,max_depth+1):\n",
    "      if d<3:\n",
    "         texttemplate = \"%{z:.2f}\"\n",
    "      else: texttemplate = \"\"\n",
    "      fig.add_trace(\n",
    "         go.Histogram2d(x=fig_x[d], y=fig_y[d], z=fig_z[d],histfunc =\"avg\"\n",
    "            ,name = \"Depth \" + str(d)\n",
    "            ,xbins = {\"size\":(stop[0]-start[0])/fo_state.splits**d}\n",
    "            ,ybins = {\"size\":(stop[1]-start[1])/fo_state.splits**d}\n",
    "            #,color_continuous_scale=\"gray\"\n",
    "            ,colorscale = [[0, \"#000000\"], [0.25,\"#5B8C5A\"], [0.5, \"#56638A\"],  [0.75, \"#EC7316\"], [1, \"#B10909\"]] # [0.5, \"#56638A\" ],\n",
    "            ,zmax = 1\n",
    "            ,zmin = 0\n",
    "            ,texttemplate = texttemplate\n",
    "            ,textfont=dict(color=\"#FFFFFF\")\n",
    "            ,colorbar = dict(\n",
    "                        tickmode=\"array\",\n",
    "                        tickvals=[0,0.25,0.5,0.75,1],\n",
    "                        tick0=0,\n",
    "                        #dtick=0.1,\n",
    "                        #nticks=5,\n",
    "                        #showticklabels=show_legend,\n",
    "                        #len=(1-colorbar_padding)/max_depth,\n",
    "                        #y= 1-((1)/max_depth)*(d-1)-(d-1)*vertical_spacing/10,# - (top_space*2/(plot_pixels*n_plots)),\n",
    "                        #yanchor=\"top\",\n",
    "                        tickformat = \".2f\",\n",
    "                        #title = str(d)\n",
    "         )\n",
    "            )\n",
    "         ,row=d,col=1)\n",
    "   show_legend = False\n",
    "      #fig.add_trace(go.Scatter(x=[start,stop], y=[max(y),max(y)], line=dict(color='royalblue', width=2, dash='dash'),showlegend=False,marker={\"color\":\"blue\"}),row=d+1,col=1)\n",
    "\n",
    "   #update fig layout\n",
    "   #fig.update_layout(barmode='stack')\n",
    "   fig.update_layout(margin=dict(l=10, r=10, t=top_space, b=20)\n",
    "      ,width=plot_pixels+100\n",
    "      ,height=plot_pixels*n_plots\n",
    "      ,autosize=False\n",
    "      ,plot_bgcolor='rgba(0,0,0,0)'\n",
    "      #,title={\"text\":\"2D Function analysis\"}\n",
    "                ,legend=dict(\n",
    "                    title = \"Formula\",\n",
    "                    orientation=\"h\",\n",
    "                    yanchor=\"top\",\n",
    "                    y=-0.65,\n",
    "                    xanchor=\"center\",\n",
    "                    x=0.5,  \n",
    "                    font = dict(family = \"Arial\", size = 14, color = \"black\"),\n",
    "                    bordercolor=\"LightSteelBlue\",\n",
    "                    borderwidth=2,\n",
    "                    itemsizing='trace',\n",
    "                    itemwidth = 30\n",
    "                    )  \n",
    "                    )\n",
    "   #fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='black')\n",
    "   #fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
    "   #fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
    "   # fig.update_xaxes(range=[start,stop])\n",
    "   fig.update_xaxes(range=[start[0],stop[0]])\n",
    "   fig.update_yaxes(range=[start[1],stop[1]])\n",
    "   \n",
    "\n",
    "   return fig\n",
    "\n",
    "branching_factor = 2\n",
    "ranges = [[0,1],[0,1]]\n",
    "random_player = RandomPlayer()\n",
    "for f_idx in [5, 6,7,8,9,10]:\n",
    "    state = FunctionOptimisationState(players=[random_player], function=f_idx, ranges=ranges, splits=branching_factor)\n",
    "\n",
    "    fig = plot_surface(state)\n",
    "    fig.show()\n",
    "\n",
    "    fig = fo_function_analysis_2d(state, max_depth=5,minimum_step_limit=0.001)\n",
    "    fig.show()\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ecbf9c18c0d04a2116424ae9aa6ca1f2cdd5cba2daaa9a1f143185bb59456a8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
